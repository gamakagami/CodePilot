import axios from "axios";
import { servicesConfig } from "../config/services.config";
import { AnalyzePRRequest, OrchestratorResponse } from "../types/orchestrator.types";
import { AnalysisResult } from "../models/analysis-result.model";
import { analyticsTrackerService } from "./analytics-tracker.service";

export class OrchestratorService {
  
  /**
   * Limit repoContext size to prevent payload from being too large
   * - Limits number of files (max 50)
   * - Limits content size per file (max 5000 chars)
   */
  private limitRepoContext(repoContext?: Array<{ path: string; content: string }>): Array<{ path: string; content: string }> | null {
    if (!repoContext || repoContext.length === 0) {
      return null;
    }
    
    // Limit to 50 files max
    const limitedFiles = repoContext.slice(0, 50);
    
    // Limit content size per file to 5000 chars
    const processedFiles = limitedFiles.map(file => ({
      path: file.path,
      content: file.content && file.content.length > 5000 
        ? file.content.substring(0, 5000) + '\n... (truncated for size)'
        : file.content || ''
    }));
    
    if (repoContext.length > 50) {
      console.log(`‚ö†Ô∏è [ORCHESTRATOR] Repo context limited from ${repoContext.length} to 50 files`);
    }
    
    return processedFiles;
  }
  
  async analyzePR(
  request: AnalyzePRRequest, 
  userId: string,
  repositoryFullName?: string,
  prId?: number,
  prUrl?: string
): Promise<OrchestratorResponse> {
  const startTime = Date.now();
  
  try {
    console.log("üöÄ Starting PR analysis pipeline...");

    // üîç DIAGNOSTIC: Log context size
    console.log('üì• [ORCHESTRATOR] Received analysis request:');
    console.log(`   - Code length: ${request.code?.length || 0}`);
    console.log(`   - Repo Context: ${request.repoContext?.length || 0} files included`);
    
    // Single call to analysis service (which now includes prediction and review)
    console.log("üöÄ Analyzing code with prediction and review (all-in-one)...");
    const analysisStartTime = Date.now();
    
    // Pass 'request' which now contains 'repoContext' and 'repositoryFullName'
    const analysisResponse = await this.callAnalysisService(request, repositoryFullName);
    
    const analysisDuration = Date.now() - analysisStartTime;
    console.log(`‚úÖ Complete analysis (analysis + prediction + review) finished (${analysisDuration}ms)`);
    
    // Extract all results from the unified response
    const analysisData = analysisResponse.data || analysisResponse;
    const predictionData = analysisData.prediction;
    const reviewData = analysisData.review;
    
    console.log(`üîç [ORCHESTRATOR] Unified response structure:`, {
      hasAnalysis: !!analysisData,
      hasPrediction: !!predictionData,
      hasReview: !!reviewData,
      dataKeys: analysisData ? Object.keys(analysisData) : 'no data'
    });
    
    // Calculate total duration
    const totalDuration = Date.now() - startTime;
    
    // Combine results with performance metrics
    console.log('üì¶ Combining all results...');
    const result = this.combineResults(
      analysisData,
      predictionData,
      reviewData,
      {
        totalDuration,
        analysisDuration,
        predictionDuration: 0, // Included in analysis duration
        reviewDuration: 0 // Included in analysis duration
      }
    );
    
    console.log('üíæ Storing analysis result...');
    // Store the results in database
    await this.storeAnalysisResult(
      userId,
      result,
      request,
      repositoryFullName,
      prId,
      prUrl
    );
    
    // Update user analytics
    await analyticsTrackerService.updateAfterAnalysis(
      userId,
      repositoryFullName || "unknown",
      result.performance.totalDuration
    );
    
    console.log(`üéâ Pipeline complete in ${totalDuration}ms`);
    
    return {
      success: true,
      data: result
    };
    
  } catch (error: any) {
    console.error("‚ùå Pipeline error:", error.message);
    console.error("Stack trace:", error.stack);
    
    return {
      success: false,
      error: error.message || "Pipeline failed"
    };
  }
}

  private async storeAnalysisResult(
    userId: string,
    result: any,
    request: AnalyzePRRequest,
    repositoryFullName?: string,
    prId?: number,
    prUrl?: string
  ) {
    try {
      const analysisResult = new AnalysisResult({
        userId,
        fileId: result.fileId,
        repositoryFullName: repositoryFullName || "unknown",
        prId,
        prUrl,
        timestamp: new Date(result.timestamp),
        
        metrics: {
          linesOfCode: result.analysis.metrics.linesOfCode,
          cyclomaticComplexity: result.analysis.metrics.cyclomaticComplexity,
          maintainabilityIndex: result.analysis.metrics.maintainabilityIndex,
          linesAdded: request.linesAdded || 0,
          linesDeleted: request.linesDeleted || 0,
          filesChanged: request.filesChanged || 1
        },
        
        prediction: result.prediction,
        review: result.review,
        overall: result.overall,
        
        developer: request.developer,
        buildDuration: result.performance.totalDuration,
        codeCoverageChange: request.codeCoverageChange,
        previousFailureRate: request.previousFailureRate
      });
      
      await analysisResult.save();
      console.log(`Analysis result stored for user ${userId}`);
    } catch (error) {
      console.error("Failed to store analysis result:", error);
    }
  }
  
  // Replace the callAnalysisService method with this improved version:

private async callAnalysisService(
  request: AnalyzePRRequest,
  repositoryFullName?: string
) {

  console.log(
  "üîç [ORCHESTRATOR] Analysis URL:",
  servicesConfig.analysis.url
);

  // Ensure repoContext and repositoryFullName are included in the POST body to the AI service
  const payload = {
    code: request.code,
    fileId: request.fileId,
    developer: request.developer,
    repoContext: request.repoContext,
    repositoryFullName: repositoryFullName || request.repositoryFullName,
    linesAdded: request.linesAdded,
    linesDeleted: request.linesDeleted,
    filesChanged: request.filesChanged,
    codeCoverageChange: request.codeCoverageChange,
    buildDuration: request.buildDuration,
    previousFailureRate: request.previousFailureRate
  };

  // Ensure proper URL construction (handle trailing slashes)
  const baseUrl = servicesConfig.analysis.url.endsWith('/') 
    ? servicesConfig.analysis.url.slice(0, -1) 
    : servicesConfig.analysis.url;
  const endpoint = servicesConfig.analysis.endpoints.analyze.startsWith('/')
    ? servicesConfig.analysis.endpoints.analyze
    : `/${servicesConfig.analysis.endpoints.analyze}`;
  const fullUrl = `${baseUrl}${endpoint}`;
  
  console.log(`\nüì§ [ORCHESTRATOR] Sending data to CODE ANALYSIS SERVICE:`);
  console.log(`   URL: ${fullUrl}`);
  console.log(`   Payload structure:`, {
    code: payload.code ? `${payload.code.length} characters` : 'missing',
    fileId: payload.fileId,
    developer: payload.developer,
    repoContext: payload.repoContext ? `${payload.repoContext.length} files` : 'none',
    repositoryFullName: payload.repositoryFullName || 'not provided',
    linesAdded: payload.linesAdded,
    linesDeleted: payload.linesDeleted,
    filesChanged: payload.filesChanged,
    codeCoverageChange: payload.codeCoverageChange,
    buildDuration: payload.buildDuration,
    previousFailureRate: payload.previousFailureRate
  });
  console.log(`   Full payload (first 500 chars of code):`, {
    ...payload,
    code: payload.code ? payload.code.substring(0, 500) + '...' : 'missing'
  });

  const response = await axios.post(
    fullUrl, 
    payload,
    { timeout: 60000 } // Give it more time to process context
  );

  console.log(`‚úÖ [ORCHESTRATOR] Analysis service responded successfully`);
  console.log(`   - Response keys:`, Object.keys(response.data || {}));
  if (response.data?.data) {
    const analysisData = response.data.data;
    console.log(`   - Analysis data preview:`, {
      fileId: analysisData.fileId,
      timestamp: analysisData.timestamp,
      structure: {
        functionCount: analysisData.structure?.functionCount,
        importCount: analysisData.structure?.importCount
      },
      metrics: {
        totalLines: analysisData.metrics?.totalLines,
        cyclomaticComplexity: analysisData.metrics?.cyclomaticComplexity,
        complexityRating: analysisData.metrics?.complexityRating
      },
      dependencies: {
        direct: analysisData.dependencies?.direct?.length || 0,
        reverse: analysisData.dependencies?.reverse?.length || 0,
        hasCycles: analysisData.dependencies?.hasCycles
      },
      mernPatterns: {
        hasErrorHandling: analysisData.mernPatterns?.errorHandling?.hasErrorHandling,
        usesExpress: analysisData.mernPatterns?.express?.usesExpress,
        usesMongoDB: analysisData.mernPatterns?.database?.usesMongoDB
      },
      warnings: analysisData.warnings?.length || 0,
      recommendations: analysisData.recommendations?.length || 0,
      qualityScore: analysisData.qualityScore
    });
  } else {
    console.log(`   - Response structure preview:`, JSON.stringify(response.data, null, 2).slice(0, 1000));
  }

  return response.data;
}

// Also improve the other service calls similarly:

private async callPredictionService(analysis: any, code?: string, repoContext?: Array<{ path: string; content: string }>) {
  const url = `${servicesConfig.prediction.url}${servicesConfig.prediction.endpoints.predict}`;
  
  // Build payload with original code and full codebase context included (same as analysis service)
  const payload = {
    ...analysis,
    originalCode: code || null,  // Include the original PR code
    repoContext: repoContext || null  // Include the full codebase context (unlimited, like analysis service)
  };
  
  console.log(`\nüì§ [ORCHESTRATOR] Sending data to FAILURE PREDICTION SERVICE:`);
  console.log(`   URL: ${url}`);
  console.log(`   Payload structure:`, {
    fileId: analysis?.fileId || 'missing',
    timestamp: analysis?.timestamp || 'missing',
    originalCode: code ? `${code.length} characters` : 'not provided',
    repoContext: repoContext ? `${repoContext.length} files` : 'not provided',
    metrics: analysis?.metrics ? {
      totalLines: analysis.metrics.totalLines,
      cyclomaticComplexity: analysis.metrics.cyclomaticComplexity,
      functionCount: analysis.metrics.functionCount
    } : 'missing',
    mernPatterns: analysis?.mernPatterns ? Object.keys(analysis.mernPatterns) : 'missing',
    dependencies: analysis?.dependencies ? {
      direct: analysis.dependencies.direct?.length || 0,
      reverse: analysis.dependencies.reverse?.length || 0,
      hasCycles: analysis.dependencies.hasCycles
    } : 'missing',
    warnings: analysis?.warnings ? `${analysis.warnings.length} warnings` : 'none',
    recommendations: analysis?.recommendations ? `${analysis.recommendations.length} recommendations` : 'none'
  });
  console.log(`   Full payload keys:`, Object.keys(payload));
  
  // Show preview with code truncated for logging
  const previewPayload = {
    ...payload,
    originalCode: code ? code.substring(0, 500) + '...' : 'not provided',
    repoContext: repoContext ? `${repoContext.length} files (content truncated in preview)` : 'not provided'
  };
  console.log(`   Full payload preview:`, JSON.stringify(previewPayload, null, 2).substring(0, 1000));
  
  try {
    const response = await axios.post(url, payload, {  // Send payload with code
      timeout: 30000,
      headers: {
        'Content-Type': 'application/json'
      }
    });
    
    console.log('‚úÖ [ORCHESTRATOR] Prediction service responded successfully');
    console.log('   - Prediction raw response keys:', Object.keys(response.data));
    console.log('   - Prediction data preview:', JSON.stringify(response.data, null, 2).slice(0, 1500));
    return response.data;
    
  } catch (error: any) {
    console.error('‚ùå [ORCHESTRATOR] Prediction service error:');
    
    if (error.response) {
      console.error('   - Status:', error.response.status);
      console.error('   - Data:', error.response.data);
      
      const errorMessage = error.response.data?.error 
        || error.response.data?.message 
        || 'Unknown error';
      
      throw new Error(`Prediction service error (${error.response.status}): ${errorMessage}`);
      
    } else if (error.request) {
      throw new Error(`Prediction service unavailable at ${url}`);
    } else {
      throw new Error(`Prediction request failed: ${error.message}`);
    }
  }
}
  
  private async callReviewService(analysis: any, prediction: any, code?: string, repoContext?: Array<{ path: string; content: string }>) {
  const url = `${servicesConfig.review.url}${servicesConfig.review.endpoints.review}`;
  
  // Transform analysis service response to match review service expected format
  // Analysis service returns: { structure: { functions, imports }, metrics: {...}, ... }
  // Review service expects: { functions: [...], imports: [...], metrics: { functionCount, ... }, ... }
  
  const functions = analysis.structure?.functions || analysis.functions || [];
  const imports = analysis.structure?.imports || analysis.imports || [];
  
  // Build metrics object with functionCount (review service expects this)
  const metrics = {
    ...(analysis.metrics || {}),
    functionCount: analysis.structure?.functionCount || analysis.metrics?.functionCount || functions.length,
    importCount: analysis.structure?.importCount || analysis.metrics?.importCount || imports.length
  };
  
  // Transform mernPatterns from nested structure to flat structure if needed
  let mernPatterns = analysis.mernPatterns || {};
  if (mernPatterns.errorHandling || mernPatterns.express || mernPatterns.database) {
    // Flatten the nested structure to match what review service might expect
    mernPatterns = {
      ...mernPatterns,
      hasErrorHandling: mernPatterns.errorHandling?.hasErrorHandling || mernPatterns.hasErrorHandling || false,
      hasValidation: mernPatterns.validation?.hasValidation || mernPatterns.hasValidation || false,
      usesMongoDB: mernPatterns.database?.usesMongoDB || mernPatterns.usesMongoDB || false,
      usesExpress: mernPatterns.express?.usesExpress || mernPatterns.usesExpress || false,
      potentialIssues: mernPatterns.potentialIssues || []
    };
  }
  
  // Transform dependencies structure
  let dependencies = analysis.dependencies || {};
  if (dependencies.directDependencies || dependencies.reverseDependencies) {
    dependencies = {
      ...dependencies,
      direct: dependencies.directDependencies || dependencies.direct || [],
      reverse: dependencies.reverseDependencies || dependencies.reverse || [],
      hasCycles: dependencies.hasCycles || false
    };
  }
  
  const reviewPayload = {
    analysis: {
      fileId: analysis.fileId,
      timestamp: analysis.timestamp,
      // Review service expects functions and imports at top level
      functions: functions,
      imports: imports,
      metrics: metrics,
      mernPatterns: mernPatterns,
      dependencies: dependencies,
      // Include Pinecone similarity insights
      similarPatterns: analysis.similarPatterns || [],
      warnings: analysis.warnings || [],
      recommendations: analysis.recommendations || [],
      qualityScore: analysis.qualityScore
    },
    prediction: {
      predicted_failure: prediction.predicted_failure,
      failure_probability: prediction.failure_probability,
      will_fail: prediction.will_fail,
      confidence: prediction.confidence,
      // include rationale so review service can produce issues
      reasoning: prediction.reasoning
    },
    code: code, // Pass the actual PR code
    repoContext: repoContext || null // Pass the full codebase context (unlimited, like analysis service)
  };
  
  try {
    console.log(`\nüì§ [ORCHESTRATOR] Sending data to REVIEW GENERATION SERVICE:`);
    console.log(`   URL: ${url}`);
    console.log(`   Payload structure:`, {
      analysis: {
        fileId: reviewPayload.analysis.fileId,
        timestamp: reviewPayload.analysis.timestamp,
        metrics: reviewPayload.analysis.metrics ? {
          totalLines: reviewPayload.analysis.metrics.totalLines,
          cyclomaticComplexity: reviewPayload.analysis.metrics.cyclomaticComplexity,
          avgFunctionLength: reviewPayload.analysis.metrics.avgFunctionLength,
          functionCount: reviewPayload.analysis.metrics.functionCount,
          complexityRating: reviewPayload.analysis.metrics.complexityRating
        } : 'missing',
        functions: Array.isArray(reviewPayload.analysis.functions) ? `${reviewPayload.analysis.functions.length} functions` : 'not an array',
        imports: Array.isArray(reviewPayload.analysis.imports) ? `${reviewPayload.analysis.imports.length} imports` : 'not an array',
        mernPatterns: reviewPayload.analysis.mernPatterns ? {
          keys: Object.keys(reviewPayload.analysis.mernPatterns),
          hasErrorHandling: reviewPayload.analysis.mernPatterns.hasErrorHandling,
          usesExpress: reviewPayload.analysis.mernPatterns.usesExpress,
          usesMongoDB: reviewPayload.analysis.mernPatterns.usesMongoDB
        } : 'missing',
        dependencies: reviewPayload.analysis.dependencies ? {
          direct: Array.isArray(reviewPayload.analysis.dependencies.direct) ? reviewPayload.analysis.dependencies.direct.length : 0,
          reverse: Array.isArray(reviewPayload.analysis.dependencies.reverse) ? reviewPayload.analysis.dependencies.reverse.length : 0,
          hasCycles: reviewPayload.analysis.dependencies.hasCycles
        } : 'missing',
        similarPatterns: Array.isArray(reviewPayload.analysis.similarPatterns) ? {
          count: reviewPayload.analysis.similarPatterns.length,
          patterns: reviewPayload.analysis.similarPatterns.map((p: any) => ({
            id: p.id,
            similarityScore: p.similarityScore || p.score,
            hasMetadata: !!p.metadata
          }))
        } : 'missing',
        warnings: Array.isArray(reviewPayload.analysis.warnings) ? `${reviewPayload.analysis.warnings.length} warnings` : 'missing',
        recommendations: Array.isArray(reviewPayload.analysis.recommendations) ? `${reviewPayload.analysis.recommendations.length} recommendations` : 'missing',
        qualityScore: reviewPayload.analysis.qualityScore
      },
      prediction: {
        predicted_failure: reviewPayload.prediction.predicted_failure,
        failure_probability: reviewPayload.prediction.failure_probability,
        will_fail: reviewPayload.prediction.will_fail,
        confidence: reviewPayload.prediction.confidence,
        reasoning: reviewPayload.prediction.reasoning ? `${reviewPayload.prediction.reasoning.substring(0, 100)}...` : 'missing'
      },
      code: code ? `${code.length} characters` : 'missing',
      repoContext: repoContext ? `${repoContext.length} files` : 'missing'
    });
    console.log(`   Full payload preview:`, JSON.stringify({
      ...reviewPayload,
      code: reviewPayload.code ? reviewPayload.code.substring(0, 500) + '...' : 'missing'
    }, null, 2).substring(0, 1500));
    
    const response = await axios.post(url, reviewPayload, { timeout: 60000 });
    
    console.log('üîç [ORCHESTRATOR] Review service responded');
    console.log('   - Response keys:', Object.keys(response.data));
    
    // Log the full structure for debugging
    const responsePreview = JSON.stringify(response.data, null, 2).substring(0, 1000);
    console.log('   - Response structure preview:', responsePreview);
    
    // ‚úÖ Extract the review object based on the actual response structure
    let reviewData;
    
    // Check all possible structures
    if (response.data.data?.review) {
      // Structure: { success: true, data: { review: {...} } }
      console.log('‚úÖ [ORCHESTRATOR] Found review at: response.data.data.review');
      reviewData = response.data.data.review;
    } 
    else if (response.data.review) {
      // Structure: { success: true, review: {...} }
      console.log('‚úÖ [ORCHESTRATOR] Found review at: response.data.review');
      reviewData = response.data.review;
    } 
    else if (response.data.data && typeof response.data.data === 'object' && response.data.data.summary) {
      // Structure: { success: true, data: { summary: "...", issues: [...] } }
      console.log('‚úÖ [ORCHESTRATOR] Found review at: response.data.data (has summary)');
      reviewData = response.data.data;
    } 
    else if (response.data.summary) {
      // Structure: { success: true, summary: "...", issues: [...] }
      console.log('‚úÖ [ORCHESTRATOR] Found review at: response.data (has summary)');
      reviewData = response.data;
    } 
    else {
      // Last resort: try to use data or the whole response
      console.warn('‚ö†Ô∏è  [ORCHESTRATOR] Could not find review in expected locations, using fallback');
      reviewData = response.data.data || response.data;
    }
    
    // Validate we got something useful
    if (!reviewData || typeof reviewData !== 'object') {
      console.error('‚ùå [ORCHESTRATOR] Failed to extract valid review data');
      console.error('Response was:', response.data);
      throw new Error('Review service returned invalid data structure');
    }
    
    // Check for required fields
    if (!reviewData.summary) {
      console.warn('‚ö†Ô∏è  [ORCHESTRATOR] Review data missing summary field');
    }
    
    if (!reviewData.issues) {
      console.warn('‚ö†Ô∏è  [ORCHESTRATOR] Review data missing issues field, adding empty array');
      reviewData.issues = [];
    }
    
    console.log('‚úÖ [ORCHESTRATOR] Review data extracted successfully:');
    console.log('   - Has summary:', !!reviewData.summary);
    console.log('   - Issues is array:', Array.isArray(reviewData.issues));
    console.log('   - Issues count:', Array.isArray(reviewData.issues) ? reviewData.issues.length : 'not an array');
    console.log('   - Risk level:', reviewData.riskLevel);
    console.log('   - Should merge:', reviewData.shouldMerge);
    
    // üîç DIAGNOSTIC: Log first issue if exists
    if (Array.isArray(reviewData.issues) && reviewData.issues.length > 0) {
      console.log('   - First issue structure:');
      console.log(JSON.stringify(reviewData.issues[0], null, 2));
    } else {
      console.log('   ‚ÑπÔ∏è  No issues in review data');
    }
    
    return reviewData;
    
  } catch (error: any) {
    console.error('‚ùå [ORCHESTRATOR] Review service error:', error.message);
    if (error.response) {
      console.error('   - Response status:', error.response.status);
      console.error('   - Response data:', error.response.data);
    }
    throw new Error(`Review generation failed: ${error.response?.data?.error || error.message}`);
  }
}
  
  private combineResults(
  analysis: any, 
  prediction: any, 
  review: any,
  performance: {
    totalDuration: number;
    analysisDuration: number;
    predictionDuration: number;
    reviewDuration: number;
  }
) {
  console.log('üîç [ORCHESTRATOR] Combining results...');
  
  // ‚úÖ Validate inputs
  if (!review || typeof review !== 'object') {
    console.error('‚ùå [ORCHESTRATOR] Invalid review object passed to combineResults');
    throw new Error('Cannot combine results: review is invalid');
  }
  
  // Ensure review has required fields with defaults
  const safeReview = {
    summary: review.summary || 'No summary available',
    riskLevel: review.riskLevel || 'unknown',
    shouldMerge: review.shouldMerge ?? true,
    issues: Array.isArray(review.issues) ? review.issues : [],
    recommendations: Array.isArray(review.recommendations) ? review.recommendations : [],
    codeQuality: review.codeQuality || { score: 50, strengths: [], improvementAreas: [] }
  };
  
  console.log('üîç [ORCHESTRATOR] Review validation:');
  console.log('   - Issues:', safeReview.issues.length);
  console.log('   - Recommendations:', safeReview.recommendations.length);
  
  const criticalIssuesCount = safeReview.issues.filter(
    (issue: any) => issue.severity === "critical" || issue.severity === "high"
  ).length;
  
  console.log('   - Critical issues:', criticalIssuesCount);
  
  const canMerge = 
    safeReview.shouldMerge && 
    prediction.failure_probability < 0.7 &&
    criticalIssuesCount === 0;
  
  const requiresReview = 
    prediction.failure_probability > 0.4 ||
    criticalIssuesCount > 0 ||
    analysis.metrics.cyclomaticComplexity > 15;
  
  const toSeconds = (ms: number) => parseFloat((ms / 1000).toFixed(2));
  
  const result = {
    fileId: analysis.fileId,
    timestamp: new Date().toISOString(),
    
    analysis: {
      metrics: analysis.metrics,
      mernPatterns: analysis.mernPatterns,
      dependencies: analysis.dependencies,
      warnings: analysis.warnings || []
    },
    
    prediction: {
      predicted_failure: prediction.predicted_failure,
      failure_probability: prediction.failure_probability,
      will_fail: prediction.will_fail,
      confidence: prediction.confidence,
      recommendation: prediction.recommendation
    },
    
    review: {
      summary: safeReview.summary,
      riskLevel: safeReview.riskLevel,
      shouldMerge: safeReview.shouldMerge,
      issues: safeReview.issues,
      recommendations: safeReview.recommendations,
      codeQuality: safeReview.codeQuality
    },
    
    overall: {
      canMerge,
      requiresReview,
      criticalIssuesCount
    },
    
    performance: {
      totalDuration: toSeconds(performance.totalDuration),
      analysisDuration: toSeconds(performance.analysisDuration),
      predictionDuration: toSeconds(performance.predictionDuration),
      reviewDuration: toSeconds(performance.reviewDuration),
      averageDuration: toSeconds(
        (performance.analysisDuration + performance.predictionDuration + performance.reviewDuration) / 3
      )
    }
  };
  
  console.log('‚úÖ [ORCHESTRATOR] Results combined successfully');
  console.log('   - result.review.issues count:', result.review.issues.length);
  
  return result;
}

  async getAnalysisHistory(userId: string, limit: number = 100) {
    return await AnalysisResult.find({ userId })
      .sort({ timestamp: -1 })
      .limit(limit)
      .lean();
  }
  
  async getRepositoryAnalyses(repositoryFullName: string, userId: string) {
    return await AnalysisResult.find({ 
      repositoryFullName,
      userId 
    })
      .sort({ timestamp: -1 })
      .lean();
  }
  
  async getMetricsHistory(userId: string, periodMonths: number = 6) {
    const startDate = new Date();
    startDate.setMonth(startDate.getMonth() - periodMonths);
    
    const results = await AnalysisResult.find({
      userId,
      timestamp: { $gte: startDate }
    })
      .sort({ timestamp: 1 })
      .lean();
    
    return results.map(r => ({
      timestamp: r.timestamp,
      accuracy: this.calculateAccuracy(r),
      failureProbability: r.prediction.failure_probability,
      buildDuration: r.buildDuration || 0
    }));
  }
  
  async getBaselineMetrics(userId: string) {
    const analyses = await AnalysisResult.find({ userId }).lean();
    
    if (analyses.length === 0) {
      return { 
        traditionalLatency: 240,
        codePilotLatency: 24,
        improvement: "10x faster"
      };
    }
    
    const validDurations = analyses
      .map(a => a.buildDuration || 0)
      .filter(d => d > 0);
    
    const avgBuildDuration = validDurations.length > 0
      ? parseFloat((validDurations.reduce((sum, d) => sum + d, 0) / validDurations.length).toFixed(2))
      : 24;
    
    const traditionalLatency = parseFloat((avgBuildDuration * 10).toFixed(2)) || 240;
    
    return {
      traditionalLatency,
      codePilotLatency: avgBuildDuration,
      improvement: `${(traditionalLatency / avgBuildDuration).toFixed(1)}x faster`
    };
  }
  
  private calculateAccuracy(result: any): number {
    const confidence = result.prediction.confidence.toLowerCase();
    
    if (confidence === 'high') return 0.90;
    if (confidence === 'medium') return 0.85;
    return 0.80;
  }

  
}

export const orchestratorService = new OrchestratorService();