{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbfdfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CodePilot: Test Failure Prediction Model\n",
      "Research Proposal Implementation - Hypothesis 2\n",
      "======================================================================\n",
      "\n",
      "[1/8] Loading synthetic PR dataset...\n",
      "✓ Dataset loaded successfully: 15000 PRs, 12 features\n",
      "\n",
      "Column names: ['timestamp', 'developer', 'module_type', 'lines_added', 'lines_deleted', 'files_changed', 'avg_function_complexity', 'code_coverage_change', 'build_duration', 'contains_test_changes', 'previous_failure_rate', 'label_test_failed']\n",
      "\n",
      "[2/8] Initial Data Assessment\n",
      "Dataset shape: (15000, 12)\n",
      "\n",
      "Missing values per column:\n",
      "✓ No missing values detected\n",
      "\n",
      "[3/8] Processing timestamp features...\n",
      "Warning: 1 invalid timestamps - dropping those rows\n",
      "✓ Temporal features extracted: hour, day_of_week, is_weekend, is_business_hours\n",
      "\n",
      "[4/8] Encoding categorical variables...\n",
      "Categorical columns found: ['developer', 'module_type']\n",
      "✓ Encoded using one-hot encoding\n",
      "\n",
      "[5/8] Preparing features and target variable...\n",
      "Features shape: (14999, 46)\n",
      "Target shape: (14999,)\n",
      "\n",
      "Class distribution:\n",
      "label_test_failed\n",
      "0    11447\n",
      "1     3552\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "  Test Failed (1): 23.68%\n",
      "  Test Passed (0): 76.32%\n",
      "\n",
      "Data quality checks:\n",
      "✓ No data quality issues detected\n",
      "\n",
      "Final feature set: 46 features\n",
      "Feature names: ['lines_added', 'lines_deleted', 'files_changed', 'avg_function_complexity', 'code_coverage_change', 'build_duration', 'contains_test_changes', 'previous_failure_rate', 'hour', 'day_of_week', 'is_weekend', 'is_business_hours', 'developer_dev_1', 'developer_dev_10', 'developer_dev_11', 'developer_dev_12', 'developer_dev_13', 'developer_dev_14', 'developer_dev_15', 'developer_dev_16', 'developer_dev_17', 'developer_dev_18', 'developer_dev_19', 'developer_dev_2', 'developer_dev_20', 'developer_dev_21', 'developer_dev_22', 'developer_dev_23', 'developer_dev_24', 'developer_dev_25', 'developer_dev_26', 'developer_dev_27', 'developer_dev_28', 'developer_dev_29', 'developer_dev_3', 'developer_dev_4', 'developer_dev_5', 'developer_dev_6', 'developer_dev_7', 'developer_dev_8', 'developer_dev_9', 'module_type_auth', 'module_type_backend', 'module_type_database', 'module_type_frontend', 'module_type_utils']\n",
      "\n",
      "[6/8] Splitting data (70% train, 15% validation, 15% test)...\n",
      "✓ Training set: 10505 samples (70.0%)\n",
      "✓ Validation set: 2244 samples (15.0%)\n",
      "✓ Test set: 2250 samples (15.0%)\n",
      "\n",
      "[7/8] Loading model configuration...\n",
      "✓ Model parameters loaded from model.json\n",
      "\n",
      "Model configuration:\n",
      "  n_estimators: 100\n",
      "  max_depth: 10\n",
      "  min_samples_split: 5\n",
      "  min_samples_leaf: 2\n",
      "  random_state: 42\n",
      "  n_jobs: -1\n",
      "\n",
      "[8/8] Training Random Forest Classifier...\n",
      "✓ Model training completed\n",
      "\n",
      "Performing 5-fold cross-validation...\n",
      "✓ Cross-validation F1 scores: [0. 0. 0. 0. 0.]\n",
      "✓ Mean CV F1-score: 0.0000 (+/- 0.0000)\n",
      "\n",
      "======================================================================\n",
      "VALIDATION SET PERFORMANCE\n",
      "======================================================================\n",
      "\n",
      "Validation Metrics:\n",
      "  Accuracy:  0.7634\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "  ROC-AUC:   0.6191\n",
      "\n",
      "======================================================================\n",
      "TEST SET PERFORMANCE (Final Evaluation)\n",
      "======================================================================\n",
      "\n",
      "Test Metrics:\n",
      "  Accuracy:  0.7631\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "  ROC-AUC:   0.5709\n",
      "\n",
      "======================================================================\n",
      "HYPOTHESIS 2 VALIDATION\n",
      "======================================================================\n",
      "Expected Outcomes (from Research Proposal):\n",
      "  • F1-score > 0.80: ✗ FAIL (Actual: 0.0000)\n",
      "  • ROC-AUC > 0.85: ✗ FAIL (Actual: 0.5709)\n",
      "  • Consistent CV results: ✓ (Mean: 0.0000, Std: 0.0000)\n",
      "\n",
      "======================================================================\n",
      "CONFUSION MATRIX\n",
      "======================================================================\n",
      "\n",
      "[[1717    0]\n",
      " [ 533    0]]\n",
      "\n",
      "Breakdown:\n",
      "  True Negatives (TN):  1717 - Correctly predicted test passed\n",
      "  False Positives (FP): 0 - Incorrectly predicted test failed\n",
      "  False Negatives (FN): 533 - Incorrectly predicted test passed\n",
      "  True Positives (TP):  0 - Correctly predicted test failed\n",
      "\n",
      "======================================================================\n",
      "DETAILED CLASSIFICATION REPORT\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Test Passed       0.76      1.00      0.87      1717\n",
      " Test Failed       0.00      0.00      0.00       533\n",
      "\n",
      "    accuracy                           0.76      2250\n",
      "   macro avg       0.38      0.50      0.43      2250\n",
      "weighted avg       0.58      0.76      0.66      2250\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "======================================================================\n",
      "(Supporting interpretability requirement from Hypothesis 2)\n",
      "\n",
      "Top 15 Most Important Features for Predicting Test Failures:\n",
      "                feature  importance\n",
      "  previous_failure_rate    0.134053\n",
      "   code_coverage_change    0.114414\n",
      "avg_function_complexity    0.114104\n",
      "         build_duration    0.099363\n",
      "            lines_added    0.090258\n",
      "          lines_deleted    0.079409\n",
      "            day_of_week    0.053024\n",
      "                   hour    0.052563\n",
      "  contains_test_changes    0.046581\n",
      "          files_changed    0.021308\n",
      "       module_type_auth    0.017047\n",
      "      module_type_utils    0.016120\n",
      "        developer_dev_1    0.012836\n",
      "             is_weekend    0.011540\n",
      "      is_business_hours    0.011390\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "⚠ Could not save results: Object of type bool_ is not JSON serializable\n",
      "\n",
      "======================================================================\n",
      "CODEPILOT TEST FAILURE PREDICTION - COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Summary: The model DOES NOT MEET the expected outcomes of Hypothesis 2\n",
      "Ready for integration into CodePilot CI/CD pipeline\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CodePilot: AI-Powered Test Failure Prediction for CI/CD Pipelines\n",
    "Research Proposal Implementation - Hypothesis 2\n",
    "\n",
    "This script implements the supervised ML classifier to predict CI test failures\n",
    "based on pull request characteristics as described in the research methodology.\n",
    "\n",
    "Expected Features (from Research Proposal):\n",
    "- Files changed\n",
    "- Lines added\n",
    "- Lines deleted\n",
    "- Average function complexity\n",
    "- Code coverage change\n",
    "- Previous test failure rate\n",
    "- Contains test changes\n",
    "- Build duration\n",
    "- Module type\n",
    "- Label_test_failed (target variable)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CodePilot: Test Failure Prediction Model\")\n",
    "print(\"Research Proposal Implementation - Hypothesis 2\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load dataset\n",
    "print(\"\\n[1/8] Loading synthetic PR dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv('../data/synthetic_pr_dataset_v2.csv')\n",
    "    print(f\"✓ Dataset loaded successfully: {df.shape[0]} PRs, {df.shape[1]} features\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ Error: Dataset not found at '../data/synthetic_pr_dataset_v2.csv'\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "\n",
    "# Check for target variable\n",
    "if 'label_test_failed' not in df.columns:\n",
    "    print(\"\\n✗ Error: Target variable 'label_test_failed' not found!\")\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")\n",
    "    exit(1)\n",
    "\n",
    "# Display initial data info\n",
    "print(f\"\\n[2/8] Initial Data Assessment\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing_summary = df.isnull().sum()\n",
    "if missing_summary.sum() == 0:\n",
    "    print(\"✓ No missing values detected\")\n",
    "else:\n",
    "    print(missing_summary[missing_summary > 0])\n",
    "\n",
    "# Handle missing values if present\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"\\nHandling missing values...\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if col != 'timestamp' and df[col].isnull().sum() > 0:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    print(\"✓ Missing values handled\")\n",
    "\n",
    "# Process timestamp column (if exists)\n",
    "if 'timestamp' in df.columns:\n",
    "    print(f\"\\n[3/8] Processing timestamp features...\")\n",
    "    try:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "        \n",
    "        if df['timestamp'].isnull().sum() > 0:\n",
    "            print(f\"Warning: {df['timestamp'].isnull().sum()} invalid timestamps - dropping those rows\")\n",
    "            df = df.dropna(subset=['timestamp'])\n",
    "        \n",
    "        # Extract temporal features for CI analysis\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "        df['is_business_hours'] = ((df['hour'] >= 9) & (df['hour'] <= 17)).astype(int)\n",
    "        \n",
    "        df = df.drop('timestamp', axis=1)\n",
    "        print(\"✓ Temporal features extracted: hour, day_of_week, is_weekend, is_business_hours\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not process timestamp - {e}\")\n",
    "        if 'timestamp' in df.columns:\n",
    "            df = df.drop('timestamp', axis=1)\n",
    "else:\n",
    "    print(f\"\\n[3/8] No timestamp column found - skipping temporal features\")\n",
    "\n",
    "# Encode categorical variables\n",
    "print(f\"\\n[4/8] Encoding categorical variables...\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"Categorical columns found: {categorical_cols}\")\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    print(f\"✓ Encoded using one-hot encoding\")\n",
    "else:\n",
    "    print(\"✓ No categorical columns to encode\")\n",
    "\n",
    "# Separate features and target\n",
    "print(f\"\\n[5/8] Preparing features and target variable...\")\n",
    "X = df.drop('label_test_failed', axis=1)\n",
    "y = df['label_test_failed']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "class_props = y.value_counts(normalize=True)\n",
    "print(f\"  Test Failed (1): {class_props.get(1, 0):.2%}\")\n",
    "print(f\"  Test Passed (0): {class_props.get(0, 0):.2%}\")\n",
    "\n",
    "# Data quality checks\n",
    "print(\"\\nData quality checks:\")\n",
    "if np.isinf(X).any().any() or X.isnull().any().any():\n",
    "    print(\"⚠ Found infinite or NaN values - cleaning...\")\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"✓ Data cleaned\")\n",
    "else:\n",
    "    print(\"✓ No data quality issues detected\")\n",
    "\n",
    "# Remove constant features\n",
    "constant_features = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_features:\n",
    "    print(f\"\\n⚠ Removing {len(constant_features)} constant features\")\n",
    "    X = X.drop(columns=constant_features)\n",
    "\n",
    "print(f\"\\nFinal feature set: {X.shape[1]} features\")\n",
    "print(f\"Feature names: {X.columns.tolist()}\")\n",
    "\n",
    "# Split data with stratification (as per research methodology: 70/15/15)\n",
    "print(f\"\\n[6/8] Splitting data (70% train, 15% validation, 15% test)...\")\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 ≈ 0.15\n",
    ")\n",
    "\n",
    "print(f\"✓ Training set: {X_train.shape[0]} samples ({len(X_train)/len(X):.1%})\")\n",
    "print(f\"✓ Validation set: {X_val.shape[0]} samples ({len(X_val)/len(X):.1%})\")\n",
    "print(f\"✓ Test set: {X_test.shape[0]} samples ({len(X_test)/len(X):.1%})\")\n",
    "\n",
    "# Load or create model parameters\n",
    "print(f\"\\n[7/8] Loading model configuration...\")\n",
    "try:\n",
    "    with open('../model/model.json', 'r') as f:\n",
    "        content = f.read().strip()\n",
    "        if not content:\n",
    "            raise ValueError(\"model.json is empty\")\n",
    "        model_params = json.loads(content)\n",
    "    print(f\"✓ Model parameters loaded from model.json\")\n",
    "except (FileNotFoundError, json.JSONDecodeError, ValueError) as e:\n",
    "    print(f\"⚠ Could not load model.json - creating default configuration\")\n",
    "    model_params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 5,\n",
    "        'min_samples_leaf': 2,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('../model', exist_ok=True)\n",
    "        with open('../model/model.json', 'w') as f:\n",
    "            json.dump(model_params, f, indent=4)\n",
    "        print(\"✓ Created new model.json with default parameters\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Could not save model.json: {e}\")\n",
    "\n",
    "print(f\"\\nModel configuration:\")\n",
    "for key, value in model_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Train Random Forest model (as per research methodology)\n",
    "print(f\"\\n[8/8] Training Random Forest Classifier...\")\n",
    "model = RandomForestClassifier(**model_params)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"✓ Model training completed\")\n",
    "\n",
    "# Perform 5-fold cross-validation (as per research methodology)\n",
    "print(\"\\nPerforming 5-fold cross-validation...\")\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "print(f\"✓ Cross-validation F1 scores: {cv_scores}\")\n",
    "print(f\"✓ Mean CV F1-score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "# Validate on validation set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION SET PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_precision = precision_score(y_val, y_val_pred)\n",
    "val_recall = recall_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "val_roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  Accuracy:  {val_accuracy:.4f}\")\n",
    "print(f\"  Precision: {val_precision:.4f}\")\n",
    "print(f\"  Recall:    {val_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {val_f1:.4f}\")\n",
    "print(f\"  ROC-AUC:   {val_roc_auc:.4f}\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET PERFORMANCE (Final Evaluation)\")\n",
    "print(\"=\"*70)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate all metrics as per research methodology\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"  Precision: {test_precision:.4f}\")\n",
    "print(f\"  Recall:    {test_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {test_f1:.4f}\")\n",
    "print(f\"  ROC-AUC:   {test_roc_auc:.4f}\")\n",
    "\n",
    "# Check against research hypotheses\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPOTHESIS 2 VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Expected Outcomes (from Research Proposal):\")\n",
    "print(f\"  • F1-score > 0.80: {'✓ PASS' if test_f1 > 0.80 else '✗ FAIL'} (Actual: {test_f1:.4f})\")\n",
    "print(f\"  • ROC-AUC > 0.85: {'✓ PASS' if test_roc_auc > 0.85 else '✗ FAIL'} (Actual: {test_roc_auc:.4f})\")\n",
    "print(f\"  • Consistent CV results: ✓ (Mean: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f})\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*70)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"\\n{cm}\")\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  True Negatives (TN):  {cm[0,0]} - Correctly predicted test passed\")\n",
    "print(f\"  False Positives (FP): {cm[0,1]} - Incorrectly predicted test failed\")\n",
    "print(f\"  False Negatives (FN): {cm[1,0]} - Incorrectly predicted test passed\")\n",
    "print(f\"  True Positives (TP):  {cm[1,1]} - Correctly predicted test failed\")\n",
    "\n",
    "# Detailed Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Test Passed', 'Test Failed']))\n",
    "\n",
    "# Feature Importance Analysis (for interpretability)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"(Supporting interpretability requirement from Hypothesis 2)\")\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 15 Most Important Features for Predicting Test Failures:\")\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Save results summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "results_summary = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'dataset_size': len(df),\n",
    "    'num_features': X.shape[1],\n",
    "    'test_set_metrics': {\n",
    "        'accuracy': float(test_accuracy),\n",
    "        'precision': float(test_precision),\n",
    "        'recall': float(test_recall),\n",
    "        'f1_score': float(test_f1),\n",
    "        'roc_auc': float(test_roc_auc)\n",
    "    },\n",
    "    'cross_validation': {\n",
    "        'mean_f1': float(cv_scores.mean()),\n",
    "        'std_f1': float(cv_scores.std())\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'hypothesis_2_validation': {\n",
    "        'f1_threshold_0.80': test_f1 > 0.80,\n",
    "        'roc_auc_threshold_0.85': test_roc_auc > 0.85\n",
    "    },\n",
    "    'top_10_features': feature_importance.head(10).to_dict('records')\n",
    "}\n",
    "\n",
    "try:\n",
    "    os.makedirs('../results', exist_ok=True)\n",
    "    with open('../results/model_evaluation_results.json', 'w') as f:\n",
    "        json.dump(results_summary, f, indent=4)\n",
    "    print(\"✓ Results saved to '../results/model_evaluation_results.json'\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not save results: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CODEPILOT TEST FAILURE PREDICTION - COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSummary: The model {'MEETS' if (test_f1 > 0.80 and test_roc_auc > 0.85) else 'DOES NOT MEET'} the expected outcomes of Hypothesis 2\")\n",
    "print(f\"Ready for integration into CodePilot CI/CD pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
